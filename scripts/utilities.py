#utility functions for the project

import requests
import json
import string
from rdflib import Graph, URIRef, Literal, Namespace, BNode
from rdflib.namespace import RDFS, RDF, OWL, XSD


def get_data_from_jsonl(filepath):
    """This function reads a jsonl file and returns a list of dictionaries"""
    data = []
    
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            data.append(json.loads(line.rstrip('None\n')))
            
    return data 


def read_generation_parameters(filepath):
    """This function reads a json file with generation parameters"""
    	
    with open(filepath, 'r', encoding='utf-8') as f:
        params = json.load(f)
        
    return params


# It is a post-processing function to shape the triples from the KnowGL output
def extract_triples(decoded_preds):
    """ decoded_preds: list of strings, each string is a decoded prediction from KnowGL. 
    len(decoded_preds) = num_return_sequences"""
    
    triples = set()
    entity_set = set()
    entity_triples = set()
    relation_set = set()
    for pred in decoded_preds:
        pred = pred.replace("<s>", "").replace("<pad>", "").replace("</s>", "").replace("[", "").replace("]", "").replace("(", "").replace(")", "") # we remove the brackets and parenthesisstrip() # remove special tokens
        if pred == '':
            continue
        
        if '$' in pred:
            pred = pred.split('$')
        else:
            pred = [pred]
            
        pred = [triple.split('|') for triple in pred]   
        
        for triple in pred:
            if len(triple) != 3:
                continue
            if triple[0] == '' or triple[1] == '' or triple[2] == '':
                continue
            
            sbj = triple[0].split('#')
            if len(sbj) != 3:
                continue
            entity_set.add(sbj[0])
            entity_triples.add((sbj[0], "label", sbj[1]))
            entity_triples.add((sbj[0], "type", sbj[2]))
            
            rel = triple[1]
            relation_set.add(rel)
            
            obj = triple[2].split('#')
            if len(obj) != 3:
                continue
            entity_set.add(obj[0])
            entity_triples.add((obj[0], "label", obj[1]))
            entity_triples.add((obj[0], "type", obj[2]))
            
            triples.add((sbj[0], rel, obj[0]))

    return triples, entity_triples, entity_set, relation_set


#function to get wikidata IDs
def call_wiki_api(item, item_type='entity'):
  if item_type == 'entity':
    url = f"https://www.wikidata.org/w/api.php?action=wbsearchentities&search={item}&language=en&format=json"
  if item_type == 'property':
    url = f"https://www.wikidata.org/w/api.php?action=wbsearchentities&search={item}&type=property&language=en&format=json"
  try:
    data = requests.get(url).json()
    # Return the first id (Could upgrade this in the future)
    return data['search'][0]['id']
  except:
    return 'no-wikiID'


def write_dict_to_json(dictionary, filepath):
    """This function writes a dictionary to a json file"""
    with open(filepath, 'w') as f:
        json.dump(dictionary, f, indent=4)
  

def write_extractions_to_jsonl(data, filepath):
    """This function writes a list of dictionaries to a jsonl file"""	
    with open(filepath, 'w', encoding='utf-8') as f:
        for line in data:
            line = json.dumps(line, f, ensure_ascii=False)
            f.write(f'{line}\n')


def get_triple_components(data):
    """This function returns entities, relations, and types
    list of dicts => sets of entities, relations, and types"""
    
    all_entities = set()
    all_relations = set()
    all_types = set()
    
    for line in data:
        entities = line['Extracted Entities']
        all_entities.update(entities)
        
        relations = line['Extracted Relations']
        all_relations.update(relations)
        
        entity_triples = line['Entity Triples and Probabilities']
        for i in entity_triples:
            triple = i[0]
            if triple[1] == 'type':
                ent_type = triple[2]
                all_types.add(ent_type)

    return all_entities, all_relations, all_types


def get_triples_list(data, target='extracted triples'):
    """This function returns lists of triples
    list of dicts => lists of triples: Extracted triples (as generated by the language model), 
                                       Wikidata triples (corresponding Wikidata IDs of the generated triples), 
                                       Entity type triples (predicate=type or label)
    """

    if target.lower() == 'extracted triples':
        line_key = 'Extracted Triples and Probabilities'
    elif target.lower() == 'wikidata triples':
        line_key = 'Wikidata Triples and Probabilities'
    elif target.lower() == 'entity type triples':
        line_key = 'Entity Triples and Probabilities'

    triple_list = []
    for line in data:
        triples = line[line_key]
        for triple in triples:
           if triple not in triple_list:
               triple_list.append(triple)
               
    return triple_list


def read_wiki_dictionaries(filepath):
    """ read json file with items and their Wikidata IDs
        return a dictionary with items as keys and Wikidata IDs as values
    """ 
    with open(filepath, 'r', encoding='utf-8') as f:
        wiki_dict = json.load(f)
        
    return wiki_dict


def remove_punctuation(text):
    """This function removes punctuation from a text"""
    return text.translate(str.maketrans('', '', string.punctuation))


def shape_relation_name(rel_string, prefix):
    """ 
    Get the generated string as the relation name and shape it to the desired format:
    => desired format: "prefix:relationName"
    """

    rel = remove_punctuation(rel_string)
    rel = rel.strip().lower().split()
    if len(rel) > 1:
        words = []
        for index, word in enumerate(rel):
            if (index % 2) == 0:
                word = word.lower()   
            else:
                word = word.capitalize()
                    
            words.append(word)
        rel = ''.join(words)
    else:
        rel = rel[0].lower()
    shaped_rel =  URIRef(prefix + rel)
    
    return shaped_rel


def shape_entity_name(entity_string, prefix):
    """ 
    Get the generated string as the entity name and shape it to the desired format:
    => desired format: "prefix:entity_name"
    """
    ent = remove_punctuation(entity_string)
    ent = ent.strip().lower().replace(' ', '_')
    ent = URIRef(prefix + ent)
    
    return ent


def shape_class_name(type_string, prefix):
    """ 
    Get the generated string as the class name and shape it to the desired format:
    => desired format: "prefix:ClassName"
    """
    type_name = remove_punctuation(type_string)
    type_name = type_name.strip().split()
    if len(type_name) > 1:
        shaped_type = []
        for x in type_name:
            if x.isupper():
                x=x.upper()
            else:
                x = x.capitalize()
            shaped_type.append(x)
        shaped_type = ''.join(shaped_type)
        shaped_type = URIRef(prefix + shaped_type)  
    else:
        shaped_type = URIRef(prefix + type_name[0].capitalize())
    
    return shaped_type


def add_triple_statements(g, subj, predicate, obj, index, probs, NS=KGL): 
    """add triple statements to the graph
    """ 
    triple_node = BNode()
    g.add((triple_node, RDF.type, NS.Triple))
    g.add((triple_node, RDF.type, RDF.Statement))
    g.add((triple_node, NS.tripleID, Literal(index, datatype=XSD.integer)))
    g.add((triple_node, NS.subject, subj))
    g.add((triple_node, NS.predicate, predicate))
    g.add((triple_node, NS.object, obj))
    g.add((triple_node, NS.probability, Literal(probs['prob'], datatype=XSD.float)))
    g.add((triple_node, NS.logProbability, Literal(probs['log_prob'], datatype=XSD.float)))