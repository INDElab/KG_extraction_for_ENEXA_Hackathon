{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythorch version:  2.0.1\n",
      "Transformers version:  4.30.1\n"
     ]
    }
   ],
   "source": [
    "#REBEL environment details:\n",
    "!python --version\n",
    "import torch\n",
    "print('Pythorch version: ', torch.__version__)\n",
    "import transformers\n",
    "print('Transformers version: ', transformers.__version__)\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is a post-processing function to shape the triples from the REBEL output\n",
    "def extract_triples(text):\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append((subject.strip(), relation.strip(), object_.strip()))\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append((subject.strip(), relation.strip(), object_.strip()))\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append((subject.strip(), relation.strip(), object_.strip()))\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we call the tokenizer and the model from the HuggingFace library\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set the generation parameters for the model\n",
    "gen_kwargs = {\n",
    "    \"max_length\": 1024,\n",
    "    \"length_penalty\": 0,\n",
    "    \"num_beams\": 10, # 10 beams is NOT the default value but we opted for it to get more diverse results\n",
    "    \"num_return_sequences\": 10, # 10 sequences is NOT the default value but we opted for it to get long tail triple extraction\n",
    "    \"return_dict_in_generate\": True, \n",
    "    \"output_scores\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The first president of the United States was George Washington.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentence, max_length=1024, padding=True, truncation=True, return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "                            inputs[\"input_ids\"].to('cuda'),\n",
    "                            attention_mask=inputs[\"attention_mask\"].to('cuda'),\n",
    "                            **gen_kwargs,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_scores = model.compute_transition_scores(\n",
    "    outputs.sequences, outputs.scores, outputs.beam_indices, normalize_logits=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 1 if model.config.is_encoder_decoder else inputs.input_ids.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_length = input_length + np.sum(transition_scores.cpu().numpy() < 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_penalty = model.generation_config.length_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_scores = transition_scores.cpu().sum(axis=1) / (output_length**length_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0801, -0.0517, -0.2450, -0.3481, -0.2088, -0.3183, -0.2210, -0.3477,\n",
      "        -0.2159, -0.2298], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(reconstructed_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08008399109045665\n",
      "0.9230388160940569\n",
      "-0.0517070356168245\n",
      "0.9496070271323342\n",
      "-0.2450245710519644\n",
      "0.782685306604258\n",
      "-0.34805148298090155\n",
      "0.7060625250751662\n",
      "-0.2088111952731484\n",
      "0.8115484453621502\n",
      "-0.31829203092134917\n",
      "0.7273903369246306\n",
      "-0.22099416255950927\n",
      "0.8017213602772665\n",
      "-0.3477042638338529\n",
      "0.7063077260696624\n",
      "-0.21589133853004092\n",
      "0.8058228590127368\n",
      "-0.22976818084716796\n",
      "0.7947178119607781\n"
     ]
    }
   ],
   "source": [
    "for s in reconstructed_scores:\n",
    "    print(s.item())\n",
    "    print(np.exp(s.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted triples: [('George Washington', 'position held', 'president of the United States')]\n",
      "Log probability: -0.08008399109045665\n",
      "Probability: 0.9230388160940569\n",
      "\n",
      "Extracted triples: [('president of the United States', 'officeholder', 'George Washington'), ('George Washington', 'position held', 'president of the United States')]\n",
      "Log probability: -0.0517070356168245\n",
      "Probability: 0.9496070271323342\n",
      "\n",
      "Extracted triples: [('president of the United States', 'officeholder', 'George Washington')]\n",
      "Log probability: -0.2450245710519644\n",
      "Probability: 0.782685306604258\n",
      "\n",
      "Extracted triples: [('United States', 'founded by', 'George Washington')]\n",
      "Log probability: -0.34805148298090155\n",
      "Probability: 0.7060625250751662\n",
      "\n",
      "Extracted triples: [('first president of the United States', 'officeholder', 'George Washington'), ('George Washington', 'position held', 'president of the United States')]\n",
      "Log probability: -0.2088111952731484\n",
      "Probability: 0.8115484453621502\n",
      "\n",
      "Extracted triples: [('first president of the United States', 'officeholder', 'George Washington')]\n",
      "Log probability: -0.31829203092134917\n",
      "Probability: 0.7273903369246306\n",
      "\n",
      "Extracted triples: [('United States', 'founded by', 'George Washington'), ('George Washington', 'position held', 'president of the United States')]\n",
      "Log probability: -0.22099416255950927\n",
      "Probability: 0.8017213602772665\n",
      "\n",
      "Extracted triples: [('United States', 'head of state', 'George Washington')]\n",
      "Log probability: -0.3477042638338529\n",
      "Probability: 0.7063077260696624\n",
      "\n",
      "Extracted triples: [('first president of the United States', 'officeholder', 'George Washington'), ('George Washington', 'position held', 'first president of the United States')]\n",
      "Log probability: -0.21589133853004092\n",
      "Probability: 0.8058228590127368\n",
      "\n",
      "Extracted triples: [('United States', 'office held by head of government', 'president'), ('George Washington', 'position held', 'president')]\n",
      "Log probability: -0.22976818084716796\n",
      "Probability: 0.7947178119607781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq, seq_score, prob in zip(outputs.sequences, reconstructed_scores, np.exp(reconstructed_scores)):\n",
    "    print(f'Extracted triples: {extract_triples(tokenizer.decode(seq, skip_special_tokens=False))}')\n",
    "    print(f'Log probability: {seq_score}')\n",
    "    print(f'Probability: {prob}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 50267 | <triplet> | -0.000 | 100.00%\n",
      "|  1655 |  George  | -0.950 | 38.69%\n",
      "|   663 |  Washington | -0.000 | 100.00%\n",
      "|  1437 |          | -0.000 | 99.99%\n",
      "| 50266 | <subj>   | 0.000 | 100.00%\n",
      "|   394 |  president | -0.004 | 99.59%\n",
      "|     9 |  of      | -0.006 | 99.37%\n",
      "|     5 |  the     | -0.000 | 100.00%\n",
      "|   315 |  United  | -0.000 | 100.00%\n",
      "|   532 |  States  | 0.000 | 100.00%\n",
      "|  1437 |          | -0.000 | 100.00%\n",
      "| 50265 | <obj>    | 0.000 | 100.00%\n",
      "|   737 |  position | -0.000 | 99.97%\n",
      "|   547 |  held    | 0.000 | 100.00%\n",
      "|     2 | </s>     | -0.000 | 99.95%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n",
      "|     1 | <pad>    | 0.000 | 100.00%\n"
     ]
    }
   ],
   "source": [
    "generated_tokens = outputs.sequences[:, input_length:]\n",
    "for tok, score in zip(generated_tokens[0], transition_scores[0]):\n",
    "    # | token | token string | logits | probability\n",
    "    print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {score.cpu().numpy():.3f} | {np.exp(score.cpu().numpy()):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(outputs.sequences_scores.cpu(), reconstructed_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
